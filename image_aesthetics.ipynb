{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33e38a5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d807140f3014219b257c09680279102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suresh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Suresh\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e87f3392f4d471c9ba188a702e56af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb35384528e4889a3cd1c9ab0daeecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea5da1a33cd4d4893a2be2c2914e268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b4df761b904e448f147d283b48c9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb8d8a866fd4f7093dd981fb23a41e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13d52f8176b475fbf16bbd4cd2ff75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b065327885494d23943cfc141b26853e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, CLIPModel, AutoModel,AutoImageProcessor\n",
    "import torch.nn as nn\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9b9066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_PIL(url_or_path):\n",
    "    if url_or_path.startswith(\"http://\") or url_or_path.startswith(\"https://\"):\n",
    "        return Image.open(requests.get(url_or_path, stream=True).raw)\n",
    "    else:\n",
    "        return Image.open(url_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005ae001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    # Compute the dot product of vec1 and vec2\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    \n",
    "    # Compute the L2 norm of vec1 and vec2\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc56039",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ImageNet Classes.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Suresh\\Desktop\\Image Aesthetics\\image_aesthetics.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Suresh/Desktop/Image%20Aesthetics/image_aesthetics.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Suresh/Desktop/Image%20Aesthetics/image_aesthetics.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m temp\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_excel(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mImageNet Classes.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Suresh/Desktop/Image%20Aesthetics/image_aesthetics.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m classes\u001b[39m=\u001b[39mtemp[\u001b[39m'\u001b[39m\u001b[39mCol_Names\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Suresh/Desktop/Image%20Aesthetics/image_aesthetics.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m classes\u001b[39m=\u001b[39m[s\u001b[39m.\u001b[39mlstrip() \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m classes]\n",
      "File \u001b[1;32mc:\\Users\\Suresh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Suresh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    456\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    458\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Suresh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     ext \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxls\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     ext \u001b[39m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1377\u001b[0m         content_or_path\u001b[39m=\u001b[39;49mpath_or_buffer, storage_options\u001b[39m=\u001b[39;49mstorage_options\n\u001b[0;32m   1378\u001b[0m     )\n\u001b[0;32m   1379\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1381\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExcel file format cannot be determined, you must specify \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1382\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39man engine manually.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Suresh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(content_or_path, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1248\u001b[0m     content_or_path \u001b[39m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1250\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1251\u001b[0m     content_or_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m, storage_options\u001b[39m=\u001b[39;49mstorage_options, is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1252\u001b[0m ) \u001b[39mas\u001b[39;00m handle:\n\u001b[0;32m   1253\u001b[0m     stream \u001b[39m=\u001b[39m handle\u001b[39m.\u001b[39mhandle\n\u001b[0;32m   1254\u001b[0m     stream\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Suresh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:795\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[0;32m    796\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[0;32m    798\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ImageNet Classes.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "temp=pd.read_excel(r\"ImageNet Classes.xlsx\")\n",
    "classes=temp['Col_Names'].tolist()\n",
    "classes=[s.lstrip() for s in classes]\n",
    "positive_classes=[]\n",
    "negative_classes=[]\n",
    "for i in range(len(classes)):\n",
    "    positive_classes.append(f\"a smashing picture, of a #{classes[i]}\")\n",
    "    negative_classes.append(f\"a horrible picture, of a #{classes[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328ccc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_inputs=processor(text=positive_classes, return_tensors=\"pt\", padding=True).to(device)\n",
    "with torch.no_grad():\n",
    "    positive_text_features = model.get_text_features(**positive_inputs)\n",
    "negative_inputs=processor(text=negative_classes, return_tensors=\"pt\", padding=True).to(device)\n",
    "with torch.no_grad():\n",
    "    negative_text_features = model.get_text_features(**negative_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2145d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "positive_prompt_vectors = np.array(positive_text_features)\n",
    " \n",
    "# # Compute the average vector\n",
    "average_positive_vector = np.mean(positive_prompt_vectors, axis=0)\n",
    "# \n",
    "negative_prompt_vectors = np.array(negative_text_features)\n",
    "# \n",
    "# # Compute the average vector\n",
    "average_negative_vector = np.mean(negative_prompt_vectors, axis=0)\n",
    " \n",
    "#with open('positive_prompt.pkl', 'wb') as f:\n",
    "    #pickle.dump(average_positive_vector, f)\n",
    "#with open('negative_prompt.pkl', 'wb') as f:\n",
    "    #pickle.dump(average_negative_vector, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hotel_positive_prompt.pkl', 'rb') as f:\n",
    "    average_positive_vector = pickle.load(f)\n",
    "with open('hotel_negative_prompt.pkl', 'rb') as f:\n",
    "    average_negative_vector = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8407938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_url):\n",
    "    #image1 = img_url   Uncomment this and comment the below line if you want to use the streamlit app\n",
    "    image1 = load_image_PIL(img_url) \n",
    "    with torch.no_grad():\n",
    "        inputs1 = processor(images=image1, return_tensors=\"pt\").to(device)\n",
    "        image_features1 = model.get_image_features(**inputs1)\n",
    "    image_vector=image_features1.numpy()\n",
    "    positive_similarity=cosine_similarity(average_positive_vector,np.transpose(image_vector))\n",
    "    negative_similarity=cosine_similarity(average_negative_vector,np.transpose(image_vector))\n",
    "    aesthetic_score=positive_similarity+(-1*negative_similarity)\n",
    "    return aesthetic_score*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "st.header('Image Aesthetics Scorer')\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=['png','jpg','jpeg'])\n",
    "picture_width = st.sidebar.slider('Picture Width', min_value=100, max_value=500)\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.subheader('Input', divider='rainbow')\n",
    "    st.image(image, caption='Uploaded Image', width=picture_width)\n",
    "\n",
    "        # Call your function with the uploaded image\n",
    "    results = predict(image)\n",
    "    \n",
    "    st.subheader('Results', divider='rainbow')\n",
    "        # Display the results\n",
    "    st.image(image, caption=results, width=picture_width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
